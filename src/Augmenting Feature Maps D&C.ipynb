{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": "true"
   },
   "source": [
    "# Table of Contents\n",
    " <p><div class=\"lev1 toc-item\"><a href=\"#The-plan\" data-toc-modified-id=\"The-plan-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>The plan</a></div><div class=\"lev2 toc-item\"><a href=\"#Results\" data-toc-modified-id=\"Results-11\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Results</a></div><div class=\"lev2 toc-item\"><a href=\"#Baseline-model\" data-toc-modified-id=\"Baseline-model-12\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Baseline model</a></div><div class=\"lev2 toc-item\"><a href=\"#Image-Augmentation\" data-toc-modified-id=\"Image-Augmentation-13\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Image Augmentation</a></div><div class=\"lev2 toc-item\"><a href=\"#Augmenting-feature-maps\" data-toc-modified-id=\"Augmenting-feature-maps-14\"><span class=\"toc-item-num\">1.4&nbsp;&nbsp;</span>Augmenting feature maps</a></div><div class=\"lev2 toc-item\"><a href=\"#Submission\" data-toc-modified-id=\"Submission-15\"><span class=\"toc-item-num\">1.5&nbsp;&nbsp;</span>Submission</a></div><div class=\"lev3 toc-item\"><a href=\"#Baseline-model\" data-toc-modified-id=\"Baseline-model-151\"><span class=\"toc-item-num\">1.5.1&nbsp;&nbsp;</span>Baseline model</a></div><div class=\"lev3 toc-item\"><a href=\"#Augmented-feature-maps\" data-toc-modified-id=\"Augmented-feature-maps-152\"><span class=\"toc-item-num\">1.5.2&nbsp;&nbsp;</span>Augmented feature maps</a></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The plan\n",
    "\n",
    "In this notebook we will look at how data augmentation in feature maps space can improve performance of a classifier. \n",
    "See the blog post on justification when we need such transformations of feature maps.\n",
    "\n",
    "To see whether we have any gains I'm going to do the following:\n",
    "\n",
    "Use VGG with fixed weights as pre-trained network and will develop three model on top of it\n",
    "\n",
    "1. The simple fully convolutional baseline model\n",
    "2. The model above trained on additional images produced by applying image augmenation of the original images\n",
    "3. The same model but trained with transformations of feature maps\n",
    "\n",
    "\n",
    "The models will be trained on small subsets(10,20,40,80 samples) of Kaggle's Cat&Dogs dataset.\n",
    "\n",
    "Then I will compare the performance of the models and their training time. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_samples, model, accuracy, sec per epoch\n",
    "results = [(10, 'bs', 0.67,0),\n",
    "    (10,'img_aug', 0.86,11),\n",
    "    (10,'fm_aug', 0.81,0),\n",
    "    #(10,'fm_aug_flex',0.74,0),\n",
    "\n",
    "    (20,'bs',0.78,0),\n",
    "    (20,'img_aug', 0.92,11),\n",
    "    (20,'fm_aug',0.92,0),\n",
    "\n",
    "    (40,'bs', 0.92, 0),\n",
    "    (40,'img_aug',0.94, 12),\n",
    "    (40,'fm_aug',0.93,0),\n",
    "\n",
    "\n",
    "    (80,'bs', 0.94, 0),\n",
    "    (80,'img_aug',0.94, 15),\n",
    "    (80,'fm_aug', 0.94, 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 4)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>bs</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>img_aug</td>\n",
       "      <td>0.86</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>fm_aug</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>bs</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>img_aug</td>\n",
       "      <td>0.92</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_samples    model  accuracy  time\n",
       "0         10       bs      0.67     0\n",
       "1         10  img_aug      0.86    11\n",
       "2         10   fm_aug      0.81     0\n",
       "3         20       bs      0.78     0\n",
       "4         20  img_aug      0.92    11"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(results, columns=['n_samples','model','accuracy','time'])\n",
    "df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(df.to_html())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.replace({'model':{'bs':'baseline','img_aug':'image augmentation','fm_aug':'feature maps augmentation'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_samples</th>\n",
       "      <th>model</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>image augmentation</td>\n",
       "      <td>0.86</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>feature maps augmentation</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20</td>\n",
       "      <td>image augmentation</td>\n",
       "      <td>0.92</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20</td>\n",
       "      <td>feature maps augmentation</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>40</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>40</td>\n",
       "      <td>image augmentation</td>\n",
       "      <td>0.94</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>40</td>\n",
       "      <td>feature maps augmentation</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>80</td>\n",
       "      <td>baseline</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>80</td>\n",
       "      <td>image augmentation</td>\n",
       "      <td>0.94</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>80</td>\n",
       "      <td>feature maps augmentation</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n_samples                      model  accuracy  time\n",
       "0          10                   baseline      0.67     0\n",
       "1          10         image augmentation      0.86    11\n",
       "2          10  feature maps augmentation      0.81     0\n",
       "3          20                   baseline      0.78     0\n",
       "4          20         image augmentation      0.92    11\n",
       "5          20  feature maps augmentation      0.92     0\n",
       "6          40                   baseline      0.92     0\n",
       "7          40         image augmentation      0.94    12\n",
       "8          40  feature maps augmentation      0.93     0\n",
       "9          80                   baseline      0.94     0\n",
       "10         80         image augmentation      0.94    15\n",
       "11         80  feature maps augmentation      0.94     0"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\n",
      "  <thead>\n",
      "    <tr style=\"text-align: right;\">\n",
      "      <th>n_samples</th>\n",
      "      <th>model</th>\n",
      "      <th>accuracy</th>\n",
      "      <th>time</th>\n",
      "    </tr>\n",
      "  </thead>\n",
      "  <tbody>\n",
      "    <tr>\n",
      "      <td>10</td>\n",
      "      <td>baseline</td>\n",
      "      <td>0.67</td>\n",
      "      <td>0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>10</td>\n",
      "      <td>image augmentation</td>\n",
      "      <td>0.86</td>\n",
      "      <td>11</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>10</td>\n",
      "      <td>feature maps augmentation</td>\n",
      "      <td>0.81</td>\n",
      "      <td>0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>20</td>\n",
      "      <td>baseline</td>\n",
      "      <td>0.78</td>\n",
      "      <td>0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>20</td>\n",
      "      <td>image augmentation</td>\n",
      "      <td>0.92</td>\n",
      "      <td>11</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>20</td>\n",
      "      <td>feature maps augmentation</td>\n",
      "      <td>0.92</td>\n",
      "      <td>0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>40</td>\n",
      "      <td>baseline</td>\n",
      "      <td>0.92</td>\n",
      "      <td>0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>40</td>\n",
      "      <td>image augmentation</td>\n",
      "      <td>0.94</td>\n",
      "      <td>12</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>40</td>\n",
      "      <td>feature maps augmentation</td>\n",
      "      <td>0.93</td>\n",
      "      <td>0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>80</td>\n",
      "      <td>baseline</td>\n",
      "      <td>0.94</td>\n",
      "      <td>0</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>80</td>\n",
      "      <td>image augmentation</td>\n",
      "      <td>0.94</td>\n",
      "      <td>15</td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "      <td>80</td>\n",
      "      <td>feature maps augmentation</td>\n",
      "      <td>0.94</td>\n",
      "      <td>0</td>\n",
      "    </tr>\n",
      "  </tbody>\n",
      "</table>\n"
     ]
    }
   ],
   "source": [
    "df\n",
    "print(df.to_html(index = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4444444444444445"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.16 / 0.36"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Francois Chollet in [his tutorial]() used Kaggle [Dogs vs Cats Redux](https://www.kaggle.com/c/dogs-vs-cats-redux-kernels-edition/data) competition data to show how to use image augmentation and pre-trained models to train a classifier small amount of data. Francois used only 2,000 (1000 cats and 1000 dogs) out of 25,000 images to achieve ... accuracy \n",
    "\n",
    "I will make the task even more challenging I will train a classifier on small number of examples starting from 5 samples per class, 10, 20, and 40 samples per class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from cat_dog.util_blog import *\n",
    "\n",
    "import math\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fpath = full_path('train/*.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#fpath = full_path('train/*.jpg')\n",
    "fpath = '../../data/cat_dog/train/*.jpg'\n",
    "img_df = pd.DataFrame({'path':glob.glob(fpath)})\n",
    "img_df['dog'] = (img_df.path.str.find('train/dog.') > 0).astype(int)\n",
    "img_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fpath = full_path('test/*.jpg')\n",
    "test_img_df = pd.DataFrame({'path':glob.glob(fpath)})\n",
    "test_img_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit, StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "test_idx, tmp_idx = next(StratifiedShuffleSplit(train_size = 0.1, test_size = 0.1, random_state= 517).split(img_df, img_df.dog))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500,)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2500,)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(80,)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, val_idx = train_test_split(tmp_idx, train_size = 80, test_size=500, random_state=801, \n",
    "                                     stratify = img_df.iloc[tmp_idx].dog)\n",
    "#next(ShuffleSplit(test_size = 0.8, random_state= 617).split(val_idx, val_idx))\n",
    "val_idx.shape\n",
    "test_idx.shape\n",
    "train_idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 2)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(80, 2)"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in [test_idx, val_idx,train_idx]:\n",
    "    img_df.loc[idx].shape\n",
    "    np.mean(img_df.loc[idx].dog)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(np.intersect1d(train_idx,test_idx))\n",
    "sum(np.intersect1d(train_idx,val_idx))\n",
    "sum(np.intersect1d(test_idx,val_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 2)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(2500, 2)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(80, 2)"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df = img_df.iloc[val_idx]\n",
    "val_df.shape\n",
    "test_df = img_df.iloc[test_idx]\n",
    "test_df.shape\n",
    "train_df = img_df.iloc[train_idx]\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((500, 374), 5),\n",
       " ((499, 375), 4),\n",
       " ((319, 240), 2),\n",
       " ((299, 240), 1),\n",
       " ((500, 365), 1),\n",
       " ((500, 332), 1),\n",
       " ((347, 500), 1),\n",
       " ((178, 184), 1),\n",
       " ((320, 440), 1),\n",
       " ((339, 260), 1)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_dims = [load_img(p).size for p in train_df.path]\n",
    "from collections import Counter\n",
    "c = Counter(img_dims)\n",
    "from operator import itemgetter\n",
    "c_sort = sorted(c.items(), key=itemgetter(1), reverse = True)\n",
    "c_sort[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23.375"
      ]
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "374/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#target_size = (500, 374)\n",
    "target_size = (374,500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((80, 374, 500, 3), (80,))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((500, 374, 500, 3), (500,))"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = prep_x_y(train_df, target_size = target_size)\n",
    "X_train.shape, y_train.shape\n",
    "\n",
    "X_val, y_val = prep_x_y(val_df, target_size = target_size)\n",
    "X_val.shape, y_val.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((500, 374, 500, 3), (500,))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "((2500, 374, 500, 3), (2500,))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X_test, y_test = prep_x_y(test_df, target_size = target_size)\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline model\n",
    "\n",
    "The first model is to set a baseline it will be a full convolution network attached to top of pre-trained VGG\n",
    "As I'm not going to use image augmenation for the baseline I will first save run VGG for train and test sets and will keep output tensors as input to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#conv_out = attach_top_to_vgg(lambda x: x, layer_name = 'block5_pool')\n",
    "#conv_out = attach_top_to_vgg(lambda x: x, layer_name = 'block5_pool')\n",
    "conv_out = attach_top_to_vgg(lambda x: x, layer_name = 'block5_conv3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(500, 23, 31, 512)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(80, 23, 31, 512)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_val = conv_out.predict(X_val, batch_size=24)\n",
    "X2_val.shape\n",
    "\n",
    "X2_train = conv_out.predict(X_train, batch_size=24)\n",
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 53.6 s, sys: 12.1 s, total: 1min 5s\n",
      "Wall time: 1min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2500, 23, 31, 512)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time X2_test = conv_out.predict(X_test, batch_size=24)\n",
    "X2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fc_bin_m1(x):\n",
    "    \"\"\"\n",
    "    Fully Convolutional binary model\n",
    "    \"\"\"\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='b1_pool')(x)\n",
    "    x = Convolution2D(256, 1, 1, activation='relu', name='conv_1x1')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Convolution2D(128, 7, 7, activation='relu', border_mode='valid', name='conv_FC1')(x)\n",
    "    x = BatchNormalization(axis=3)(x)\n",
    "    x = Convolution2D(1, 1, 1, activation='sigmoid', border_mode='valid', name='conv_FC_last')(x)\n",
    "    x = GlobalAveragePooling2D(name='avg_pool')(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (None, None, 512)\n",
    "#model = fc_bin_m2(Input(shape=input_shape), crop_size)\n",
    "m_input = Input(shape=input_shape)\n",
    "model = Model(m_input, fc_bin_m1(m_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 500 samples\n",
      "Epoch 1/20\n",
      "1s - loss: 0.5641 - acc: 0.7500 - val_loss: 1.1526 - val_acc: 0.5760\n",
      "Epoch 2/20\n",
      "0s - loss: 0.2637 - acc: 0.9375 - val_loss: 1.0563 - val_acc: 0.6660\n",
      "Epoch 3/20\n",
      "0s - loss: 0.1984 - acc: 0.9500 - val_loss: 0.5350 - val_acc: 0.7940\n",
      "Epoch 4/20\n",
      "0s - loss: 0.0950 - acc: 1.0000 - val_loss: 0.3682 - val_acc: 0.8480\n",
      "Epoch 5/20\n",
      "0s - loss: 0.1204 - acc: 0.9500 - val_loss: 0.3003 - val_acc: 0.8740\n",
      "Epoch 6/20\n",
      "0s - loss: 0.0557 - acc: 1.0000 - val_loss: 0.2795 - val_acc: 0.8840\n",
      "Epoch 7/20\n",
      "0s - loss: 0.0430 - acc: 1.0000 - val_loss: 0.2638 - val_acc: 0.8900\n",
      "Epoch 8/20\n",
      "0s - loss: 0.0354 - acc: 1.0000 - val_loss: 0.2450 - val_acc: 0.8900\n",
      "Epoch 9/20\n",
      "0s - loss: 0.0435 - acc: 0.9875 - val_loss: 0.2137 - val_acc: 0.9040\n",
      "Epoch 10/20\n",
      "0s - loss: 0.0319 - acc: 1.0000 - val_loss: 0.1816 - val_acc: 0.9100\n",
      "Epoch 11/20\n",
      "0s - loss: 0.0191 - acc: 1.0000 - val_loss: 0.1670 - val_acc: 0.9220\n",
      "Epoch 12/20\n",
      "0s - loss: 0.0165 - acc: 1.0000 - val_loss: 0.1642 - val_acc: 0.9220\n",
      "Epoch 13/20\n",
      "0s - loss: 0.0131 - acc: 1.0000 - val_loss: 0.1697 - val_acc: 0.9240\n",
      "Epoch 14/20\n",
      "0s - loss: 0.0188 - acc: 1.0000 - val_loss: 0.1755 - val_acc: 0.9180\n",
      "Epoch 15/20\n",
      "0s - loss: 0.0463 - acc: 1.0000 - val_loss: 0.1801 - val_acc: 0.9140\n",
      "Epoch 16/20\n",
      "0s - loss: 0.0101 - acc: 1.0000 - val_loss: 0.1982 - val_acc: 0.9060\n",
      "Epoch 17/20\n",
      "0s - loss: 0.0083 - acc: 1.0000 - val_loss: 0.2071 - val_acc: 0.9040\n",
      "Epoch 18/20\n",
      "0s - loss: 0.0155 - acc: 1.0000 - val_loss: 0.2049 - val_acc: 0.9040\n",
      "Epoch 19/20\n",
      "0s - loss: 0.0177 - acc: 1.0000 - val_loss: 0.1892 - val_acc: 0.9140\n",
      "Epoch 20/20\n",
      "0s - loss: 0.0069 - acc: 1.0000 - val_loss: 0.1680 - val_acc: 0.9300\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "history = model.fit(X2_train, y_train, validation_data=(X2_val, y_val),\n",
    "                    batch_size = 32,\n",
    "                    nb_epoch = 20, verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 500 samples\n",
      "Epoch 1/10\n",
      "0s - loss: 0.0047 - acc: 1.0000 - val_loss: 0.1592 - val_acc: 0.9440\n",
      "Epoch 2/10\n",
      "0s - loss: 0.0250 - acc: 1.0000 - val_loss: 0.1579 - val_acc: 0.9420\n",
      "Epoch 3/10\n",
      "0s - loss: 0.0178 - acc: 1.0000 - val_loss: 0.1599 - val_acc: 0.9460\n",
      "Epoch 4/10\n",
      "0s - loss: 0.0065 - acc: 1.0000 - val_loss: 0.1623 - val_acc: 0.9440\n",
      "Epoch 5/10\n",
      "0s - loss: 0.0031 - acc: 1.0000 - val_loss: 0.1646 - val_acc: 0.9400\n",
      "Epoch 6/10\n",
      "0s - loss: 0.0034 - acc: 1.0000 - val_loss: 0.1660 - val_acc: 0.9320\n",
      "Epoch 7/10\n",
      "0s - loss: 0.0038 - acc: 1.0000 - val_loss: 0.1673 - val_acc: 0.9320\n",
      "Epoch 8/10\n",
      "0s - loss: 0.0035 - acc: 1.0000 - val_loss: 0.1673 - val_acc: 0.9360\n",
      "Epoch 9/10\n",
      "0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1669 - val_acc: 0.9440\n",
      "Epoch 10/10\n",
      "0s - loss: 0.0022 - acc: 1.0000 - val_loss: 0.1660 - val_acc: 0.9460\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "history = model.fit(X2_train, y_train, validation_data=(X2_val, y_val),\n",
    "                    nb_epoch = 10, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 80 samples, validate on 500 samples\n",
      "Epoch 1/5\n",
      "0s - loss: 0.0021 - acc: 1.0000 - val_loss: 0.1650 - val_acc: 0.9440\n",
      "Epoch 2/5\n",
      "0s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1639 - val_acc: 0.9420\n",
      "Epoch 3/5\n",
      "0s - loss: 0.0028 - acc: 1.0000 - val_loss: 0.1627 - val_acc: 0.9440\n",
      "Epoch 4/5\n",
      "0s - loss: 0.0018 - acc: 1.0000 - val_loss: 0.1613 - val_acc: 0.9440\n",
      "Epoch 5/5\n",
      "0s - loss: 0.0048 - acc: 1.0000 - val_loss: 0.1606 - val_acc: 0.9440\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-6\n",
    "history = model.fit(X2_train, y_train, validation_data=(X2_val, y_val),\n",
    "                    nb_epoch = 5, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.19046315607689321"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.93600000000000005"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X2_test)\n",
    "pred.shape\n",
    "pred = reduce_conf(pred)\n",
    "metrics.log_loss(y_test, pred)\n",
    "pred_class = (pred > 0.5).astype('float32')\n",
    "metrics.accuracy_score(y_test, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "        0.0       0.96      0.93      0.94      1250\n",
      "        1.0       0.93      0.96      0.94      1250\n",
      "\n",
      "avg / total       0.94      0.94      0.94      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, (pred > 0.5).astype('int')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have got a very strong baseline with very simple and fast model. Thank to using pre-trained model.\n",
    "But let's see if we can improve that with image augmentation. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation\n",
    "\n",
    "We are going to use Keras ImageDataGenerator to do the following augmenations:\n",
    "\n",
    "Why those?\n",
    "Because they are common on ImageNet Challenge. And also because similar transformations could be applied to feature maps. So we are giving feature map transformations a fair chance.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "        #shear_range=0.2,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range =0.2,\n",
    "        horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of image augmentation we cannot use prepared output of VGG convolution layers. So we need to attach our model and it is the same model but the training starts from the image level. And for every batch we run the input through the all layer of VGG - it takes time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "model = attach_top_to_vgg(fc_bin_m1, layer_name = 'block5_conv3')\n",
    "#model = attach_top_to_vgg(fc_bin_m1, layer_name = 'block5_pool')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/9\n",
      "15s - loss: 0.5107 - acc: 0.7500 - val_loss: 1.7492 - val_acc: 0.5300\n",
      "Epoch 2/9\n",
      "14s - loss: 0.2671 - acc: 0.9375 - val_loss: 0.7316 - val_acc: 0.7460\n",
      "Epoch 3/9\n",
      "14s - loss: 0.1976 - acc: 0.9625 - val_loss: 0.4006 - val_acc: 0.8380\n",
      "Epoch 4/9\n",
      "14s - loss: 0.1534 - acc: 0.9875 - val_loss: 0.2385 - val_acc: 0.8880\n",
      "Epoch 5/9\n",
      "14s - loss: 0.1260 - acc: 1.0000 - val_loss: 0.2120 - val_acc: 0.8980\n",
      "Epoch 6/9\n",
      "14s - loss: 0.1063 - acc: 1.0000 - val_loss: 0.2024 - val_acc: 0.9080\n",
      "Epoch 7/9\n",
      "14s - loss: 0.0768 - acc: 1.0000 - val_loss: 0.1861 - val_acc: 0.9180\n",
      "Epoch 8/9\n",
      "14s - loss: 0.0759 - acc: 0.9875 - val_loss: 0.1771 - val_acc: 0.9220\n",
      "Epoch 9/9\n",
      "14s - loss: 0.0589 - acc: 1.0000 - val_loss: 0.1787 - val_acc: 0.9240\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    samples_per_epoch=len(X_train), nb_epoch = 9, verbose = 2,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "14s - loss: 0.0659 - acc: 1.0000 - val_loss: 0.1821 - val_acc: 0.9240\n",
      "Epoch 2/4\n",
      "14s - loss: 0.0765 - acc: 1.0000 - val_loss: 0.1803 - val_acc: 0.9220\n",
      "Epoch 3/4\n",
      "14s - loss: 0.0520 - acc: 1.0000 - val_loss: 0.1773 - val_acc: 0.9240\n",
      "Epoch 4/4\n",
      "14s - loss: 0.0560 - acc: 1.0000 - val_loss: 0.1725 - val_acc: 0.9280\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    samples_per_epoch=len(X_train), nb_epoch = 4, verbose = 2,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "14s - loss: 0.0261 - acc: 1.0000 - val_loss: 0.1549 - val_acc: 0.9500\n",
      "Epoch 2/5\n",
      "14s - loss: 0.0256 - acc: 1.0000 - val_loss: 0.1538 - val_acc: 0.9520\n",
      "Epoch 3/5\n",
      "14s - loss: 0.0309 - acc: 1.0000 - val_loss: 0.1485 - val_acc: 0.9560\n",
      "Epoch 4/5\n",
      "14s - loss: 0.0292 - acc: 1.0000 - val_loss: 0.1416 - val_acc: 0.9580\n",
      "Epoch 5/5\n",
      "14s - loss: 0.0279 - acc: 1.0000 - val_loss: 0.1405 - val_acc: 0.9600\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-6\n",
    "history = model.fit_generator(train_datagen.flow(X_train, y_train, batch_size=16),\n",
    "                    samples_per_epoch=len(X_train), nb_epoch = 5, verbose = 2,\n",
    "                    validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.16537814592011274"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.94279999999999997"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test,batch_size=24)\n",
    "pred.shape\n",
    "pred = reduce_conf(pred)\n",
    "metrics.log_loss(y_test, pred)\n",
    "pred_class = (pred > 0.5).astype('float32')\n",
    "metrics.accuracy_score(y_test, pred_class)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to be patient - training gets 100 times slower. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmenting feature maps\n",
    "\n",
    "Now we are going to apply similar spatial transformation to feature maps extracted by the pre-trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def aug_fun(x, cr = (0.1,0.1)):#crop_shape=(12,9)):\n",
    "    shape = (x.shape[1],x.shape[2]) #expects a batch of image tensors\n",
    "    crop_shape = ((int(shape[0] - cr[0]*shape[0])), (int(shape[1] - cr[1]*shape[1])))\n",
    "    #print(crop_shape)\n",
    "    stride = [0,0]\n",
    "    stride[0] = np.random.randint(shape[0] - crop_shape[0] + 1)\n",
    "    stride[1] = np.random.randint(shape[1] - crop_shape[1] + 1)\n",
    "    #print(\"sride:\", stride)\n",
    "    res = x[:,stride[0]:(crop_shape[0]+stride[0]),stride[1]:(crop_shape[1]+stride[1]),:]\n",
    "    #and random flip\n",
    "    if np.random.binomial(1,0.5):\n",
    "        #res = np.fliplr(res)\n",
    "        #res = res[:,::-1]\n",
    "        res = np.flip(res, axis = 2)\n",
    "    return res\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv_crop_gen(X, y, cr = (0.2,0.2)):\n",
    "    while True:\n",
    "        for i in np.random.permutation(X.shape[0]):\n",
    "            res = (aug_fun(X[i:i+1,::], cr), y[i:i+1])\n",
    "            yield res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def aug_fun_flex(x, cr = (0.1,0.1)):#crop_shape=(12,9)):\n",
    "    shape = (x.shape[1],x.shape[2]) #expects a batch of image tensors\n",
    "    crop_shape = (shape[0] - np.random.randint(math.ceil(cr[0]*shape[0])+1), \n",
    "                  shape[1] - np.random.randint(math.ceil(cr[1]*shape[1])+1))\n",
    "    #print(crop_shape)\n",
    "    stride = [0,0]\n",
    "    stride[0] = np.random.randint(shape[0] - crop_shape[0] + 1)\n",
    "    stride[1] = np.random.randint(shape[1] - crop_shape[1] + 1)\n",
    "    #print(\"sride:\", stride)\n",
    "    res = x[:,stride[0]:(crop_shape[0]+stride[0]),stride[1]:(crop_shape[1]+stride[1]),:]\n",
    "    #and random flip\n",
    "    if np.random.binomial(1,0.5):\n",
    "        #res = np.fliplr(res)\n",
    "        res = np.flip(res, axis = 2)\n",
    "        #res = res[:,::-1]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crop_gen_flex(X, y, cr = (0.3,0.3), batch_size = 8):\n",
    "    while True:\n",
    "        idx = np.random.permutation(X.shape[0])\n",
    "        for j in range(0, X.shape[0], batch_size):\n",
    "            #print(j)\n",
    "            b_idx = idx[j:(j+batch_size)]\n",
    "            res = (aug_fun_flex(X[b_idx,::], cr), y[b_idx])\n",
    "            yield res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gen = gen_batch_wrap(conv_crop_gen(X2_train, y_train, cr = (0.2,0.3)), batch_size = 16)\n",
    "#train_gen = crop_gen_flex_square(X2_train, y_train, cr = 0.2, flip = True, batch_size = 32)\n",
    "#train_gen = crop_gen_flex(X2_train, y_train, cr = (0.1,0.3), batch_size = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (None, None, 512)\n",
    "#model = fc_bin_m2(Input(shape=input_shape), crop_size)\n",
    "m_input = Input(shape=input_shape)\n",
    "model = Model(m_input, fc_bin_m1(m_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "1s - loss: 0.5402 - acc: 0.7250 - val_loss: 1.2674 - val_acc: 0.5460\n",
      "Epoch 2/20\n",
      "0s - loss: 0.2332 - acc: 0.9250 - val_loss: 0.9670 - val_acc: 0.6540\n",
      "Epoch 3/20\n",
      "0s - loss: 0.1521 - acc: 0.9500 - val_loss: 0.6967 - val_acc: 0.7120\n",
      "Epoch 4/20\n",
      "0s - loss: 0.1037 - acc: 1.0000 - val_loss: 0.5357 - val_acc: 0.7680\n",
      "Epoch 5/20\n",
      "0s - loss: 0.0768 - acc: 0.9875 - val_loss: 0.4241 - val_acc: 0.8180\n",
      "Epoch 6/20\n",
      "0s - loss: 0.1243 - acc: 0.9625 - val_loss: 0.3722 - val_acc: 0.8380\n",
      "Epoch 7/20\n",
      "0s - loss: 0.0387 - acc: 1.0000 - val_loss: 0.3583 - val_acc: 0.8380\n",
      "Epoch 8/20\n",
      "0s - loss: 0.1456 - acc: 0.9375 - val_loss: 0.3591 - val_acc: 0.8380\n",
      "Epoch 9/20\n",
      "0s - loss: 0.0384 - acc: 0.9875 - val_loss: 0.3298 - val_acc: 0.8440\n",
      "Epoch 10/20\n",
      "0s - loss: 0.0408 - acc: 1.0000 - val_loss: 0.2785 - val_acc: 0.8720\n",
      "Epoch 11/20\n",
      "0s - loss: 0.0247 - acc: 1.0000 - val_loss: 0.2613 - val_acc: 0.8760\n",
      "Epoch 12/20\n",
      "0s - loss: 0.0469 - acc: 0.9875 - val_loss: 0.2681 - val_acc: 0.8700\n",
      "Epoch 13/20\n",
      "0s - loss: 0.0244 - acc: 1.0000 - val_loss: 0.2762 - val_acc: 0.8700\n",
      "Epoch 14/20\n",
      "0s - loss: 0.0218 - acc: 1.0000 - val_loss: 0.2633 - val_acc: 0.8740\n",
      "Epoch 15/20\n",
      "0s - loss: 0.0255 - acc: 1.0000 - val_loss: 0.2288 - val_acc: 0.9000\n",
      "Epoch 16/20\n",
      "0s - loss: 0.0248 - acc: 1.0000 - val_loss: 0.1987 - val_acc: 0.9180\n",
      "Epoch 17/20\n",
      "0s - loss: 0.0123 - acc: 1.0000 - val_loss: 0.1833 - val_acc: 0.9260\n",
      "Epoch 18/20\n",
      "0s - loss: 0.0352 - acc: 1.0000 - val_loss: 0.1806 - val_acc: 0.9280\n",
      "Epoch 19/20\n",
      "0s - loss: 0.0321 - acc: 1.0000 - val_loss: 0.1777 - val_acc: 0.9320\n",
      "Epoch 20/20\n",
      "0s - loss: 0.0172 - acc: 1.0000 - val_loss: 0.1782 - val_acc: 0.9340\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "history = model.fit_generator(train_gen,\n",
    "                    samples_per_epoch=len(X2_train), nb_epoch = 20, verbose = 2,\n",
    "                    validation_data=(X2_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "0s - loss: 0.0291 - acc: 1.0000 - val_loss: 0.1747 - val_acc: 0.9320\n",
      "Epoch 2/10\n",
      "0s - loss: 0.0183 - acc: 1.0000 - val_loss: 0.1709 - val_acc: 0.9360\n",
      "Epoch 3/10\n",
      "0s - loss: 0.0300 - acc: 1.0000 - val_loss: 0.1707 - val_acc: 0.9380\n",
      "Epoch 4/10\n",
      "0s - loss: 0.0167 - acc: 1.0000 - val_loss: 0.1689 - val_acc: 0.9360\n",
      "Epoch 5/10\n",
      "0s - loss: 0.0310 - acc: 1.0000 - val_loss: 0.1672 - val_acc: 0.9380\n",
      "Epoch 6/10\n",
      "0s - loss: 0.0230 - acc: 1.0000 - val_loss: 0.1669 - val_acc: 0.9420\n",
      "Epoch 7/10\n",
      "0s - loss: 0.0079 - acc: 1.0000 - val_loss: 0.1689 - val_acc: 0.9340\n",
      "Epoch 8/10\n",
      "0s - loss: 0.0062 - acc: 1.0000 - val_loss: 0.1677 - val_acc: 0.9320\n",
      "Epoch 9/10\n",
      "0s - loss: 0.0345 - acc: 0.9875 - val_loss: 0.1603 - val_acc: 0.9360\n",
      "Epoch 10/10\n",
      "0s - loss: 0.0044 - acc: 1.0000 - val_loss: 0.1562 - val_acc: 0.9400\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "history = model.fit_generator(train_gen,\n",
    "                    samples_per_epoch=len(X2_train), nb_epoch = 10, verbose = 2,\n",
    "                    validation_data=(X2_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "0s - loss: 0.0192 - acc: 1.0000 - val_loss: 0.1494 - val_acc: 0.9580\n",
      "Epoch 2/5\n",
      "0s - loss: 0.0066 - acc: 1.0000 - val_loss: 0.1473 - val_acc: 0.9600\n",
      "Epoch 3/5\n",
      "0s - loss: 0.0081 - acc: 1.0000 - val_loss: 0.1456 - val_acc: 0.9580\n",
      "Epoch 4/5\n",
      "0s - loss: 0.0042 - acc: 1.0000 - val_loss: 0.1448 - val_acc: 0.9560\n",
      "Epoch 5/5\n",
      "0s - loss: 0.0026 - acc: 1.0000 - val_loss: 0.1448 - val_acc: 0.9560\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-6\n",
    "history = model.fit_generator(train_gen,\n",
    "                    samples_per_epoch=len(X2_train), nb_epoch = 5, verbose = 2,\n",
    "                    validation_data=(X2_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 1)"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.17634539513401687"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.93920000000000003"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X2_test)\n",
    "pred.shape\n",
    "pred = reduce_conf(pred)\n",
    "metrics.log_loss(y_test, pred)\n",
    "pred_class = (pred > 0.5).astype('float32')\n",
    "metrics.accuracy_score(y_test, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616, 15, 11, 512)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1500, 15, 11, 512)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.shape\n",
    "X2_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#aug_fun(X[i:i+1,::], cr = (0.3,0.1))\n",
    "pred_lst = [model.predict(aug_fun(X2_test, cr = (0.1,0.3))) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.20395648477673531,\n",
       " 0.20723488982729613,\n",
       " 0.20619762375652789,\n",
       " 0.20370713316090405,\n",
       " 0.20941270342171192,\n",
       " 0.21822943373098969,\n",
       " 0.21859982696808875,\n",
       " 0.21053252746798098,\n",
       " 0.22544415408000351,\n",
       " 0.2001515374712646]"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.20312640709616245"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.93079999999999996"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = [metrics.log_loss(y_test, reduce_conf(pr)) for pr in pred_lst] \n",
    "sc\n",
    "pred = reduce_conf(np.mean(pred_lst, axis = 0))\n",
    "metrics.log_loss(y_test, pred)\n",
    "pred_class = (pred > 0.5).astype('float32')\n",
    "metrics.accuracy_score(y_test, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 11, 512)"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_val[0,::].shape\n",
    "\n",
    "int(11 - 0.1*11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1, 9, 10, 512)"
      ]
     },
     "execution_count": 667,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    aug_fun(X2_val[:1,::], cr = (0.1,0.3)).shape\n",
    "#aug_fun((15, 11))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "\n",
    "We see that feature maps augmentation improves the score on a par of image augmentation but works on an order of magnitude faster.  \n",
    "Let's of the ultimate test an submit predictions of the baseline model and model with feature maps augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23750,)"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1250,)"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idx, val_idx = next(ShuffleSplit(test_size = 0.05, random_state= 517).split(img_df, img_df.dog))\n",
    "train_idx.shape\n",
    "val_idx.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def img_arr_gen(df, target_size):\n",
    "    for r in df.itertuples():\n",
    "        yield preprocess_image(r.path, target_size = target_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = test_df.iloc[:2]\n",
    "gen = img_arr_gen(df, target_size = target_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 374, 500, 3)"
      ]
     },
     "execution_count": 673,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = next(gen)\n",
    "tmp.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 717,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1250, 2)"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 45.6 s, sys: 5.98 s, total: 51.6 s\n",
      "Wall time: 1min 13s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1250, 11, 15, 512)"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(1250,)"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.5072"
      ]
     },
     "execution_count": 717,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = img_df.iloc[val_idx]\n",
    "#df = img_df.iloc[:4]\n",
    "df.shape\n",
    "gen = img_arr_gen(df, target_size = target_size)\n",
    "%time X2_val = conv_out.predict_generator(gen, val_samples = df.shape[0], max_q_size = 1)\n",
    "X2_val.shape\n",
    "y_val = np.array(df.dog).astype(np.float32)\n",
    "y_val.shape\n",
    "np.mean(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23750, 2)"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 14min 21s, sys: 1min 53s, total: 16min 14s\n",
      "Wall time: 23min 10s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(23750, 11, 15, 512)"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "(23750,)"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.49962106"
      ]
     },
     "execution_count": 675,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = img_df.iloc[train_idx]\n",
    "df.shape\n",
    "gen = img_arr_gen(df, target_size = target_size)\n",
    "%time X2_train = conv_out.predict_generator(gen, val_samples = df.shape[0], max_q_size = 1)\n",
    "X2_train.shape\n",
    "y_train = np.array(df.dog).astype(np.float32)\n",
    "y_train.shape\n",
    "np.mean(y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 1)"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min 32s, sys: 59.3 s, total: 8min 31s\n",
      "Wall time: 12min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(12500, 11, 15, 512)"
      ]
     },
     "execution_count": 676,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = test_img_df\n",
    "df.shape\n",
    "gen = img_arr_gen(df, target_size = target_size)\n",
    "%time X2_test = conv_out.predict_generator(gen, val_samples = df.shape[0], max_q_size = 1)\n",
    "X2_test.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (None, None, 512)\n",
    "#model = fc_bin_m2(Input(shape=input_shape), crop_size)\n",
    "m_input = Input(shape=input_shape)\n",
    "model = Model(m_input, fc_bin_m1(m_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23750 samples, validate on 1250 samples\n",
      "Epoch 1/2\n",
      "19s - loss: 0.1089 - acc: 0.9643 - val_loss: 0.0540 - val_acc: 0.9888\n",
      "Epoch 2/2\n",
      "16s - loss: 0.0729 - acc: 0.9782 - val_loss: 0.0508 - val_acc: 0.9888\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "history = model.fit(X2_train, y_train, validation_data=(X2_val, y_val),\n",
    "                    nb_epoch = 2, verbose = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 686,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 23750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "16s - loss: 0.0609 - acc: 0.9824 - val_loss: 0.0670 - val_acc: 0.9808\n",
      "Epoch 2/5\n",
      "16s - loss: 0.0552 - acc: 0.9846 - val_loss: 0.0544 - val_acc: 0.9872\n",
      "Epoch 3/5\n",
      "16s - loss: 0.0503 - acc: 0.9855 - val_loss: 0.0503 - val_acc: 0.9856\n",
      "Epoch 4/5\n",
      "16s - loss: 0.0476 - acc: 0.9874 - val_loss: 0.0491 - val_acc: 0.9912\n",
      "Epoch 5/5\n",
      "16s - loss: 0.0413 - acc: 0.9905 - val_loss: 0.0525 - val_acc: 0.9912\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "history = model.fit(X2_train, y_train, validation_data=(X2_val, y_val),\n",
    "                    nb_epoch = 5, verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Augmented feature maps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 689,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23750, 11, 15, 512)"
      ]
     },
     "execution_count": 689,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_gen = gen_batch_wrap(conv_crop_gen(X2_train, y_train), batch_size = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (None, None, 512)\n",
    "#model = fc_bin_m2(Input(shape=input_shape), crop_size)\n",
    "m_input = Input(shape=input_shape)\n",
    "model = Model(m_input, fc_bin_m1(m_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer= Adam(lr=0.001),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 707,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anmiko/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9s - loss: 0.1158 - acc: 0.9544 - val_loss: 0.0608 - val_acc: 0.9864\n",
      "Epoch 2/5\n",
      "7s - loss: 0.0785 - acc: 0.9709 - val_loss: 0.0618 - val_acc: 0.9888\n",
      "Epoch 3/5\n",
      "7s - loss: 0.0697 - acc: 0.9744 - val_loss: 0.0545 - val_acc: 0.9856\n",
      "Epoch 4/5\n",
      "7s - loss: 0.0639 - acc: 0.9773 - val_loss: 0.0568 - val_acc: 0.9832\n",
      "Epoch 5/5\n",
      "6s - loss: 0.0590 - acc: 0.9782 - val_loss: 0.0531 - val_acc: 0.9856\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-4\n",
    "history = model.fit_generator(train_gen,\n",
    "                    samples_per_epoch=len(X2_train), nb_epoch = 5, verbose = 2,\n",
    "                    validation_data=(X2_val, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 708,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anmiko/anaconda3/lib/python3.5/site-packages/keras/engine/training.py:1569: UserWarning: Epoch comprised more than `samples_per_epoch` samples, which might affect learning results. Set `samples_per_epoch` correctly to avoid this warning.\n",
      "  warnings.warn('Epoch comprised more than '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7s - loss: 0.0570 - acc: 0.9801 - val_loss: 0.0512 - val_acc: 0.9856\n",
      "Epoch 2/5\n",
      "7s - loss: 0.0510 - acc: 0.9816 - val_loss: 0.0526 - val_acc: 0.9856\n",
      "Epoch 3/5\n",
      "7s - loss: 0.0472 - acc: 0.9834 - val_loss: 0.0532 - val_acc: 0.9864\n",
      "Epoch 4/5\n",
      "7s - loss: 0.0435 - acc: 0.9848 - val_loss: 0.0509 - val_acc: 0.9872\n",
      "Epoch 5/5\n",
      "7s - loss: 0.0412 - acc: 0.9866 - val_loss: 0.0509 - val_acc: 0.9856\n"
     ]
    }
   ],
   "source": [
    "model.optimizer.lr = 1e-5\n",
    "history = model.fit_generator(train_gen,\n",
    "                    samples_per_epoch=len(X2_train), nb_epoch = 5, verbose = 2,\n",
    "                    validation_data=(X2_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#aug_fun(X[i:i+1,::], cr = (0.3,0.1))\n",
    "pred_lst = [model.predict(aug_fun(X2_test, cr = (0.1,0.3))) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 711,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_lst = [model.predict(aug_fun(X2_val, cr = (0.1,0.3))) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 712,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.054366152898222206,\n",
       " 0.054366152898222206,\n",
       " 0.073901257865875966,\n",
       " 0.058081215167045591,\n",
       " 0.050385946031659842,\n",
       " 0.055275404179841281,\n",
       " 0.051058247101306915,\n",
       " 0.050474743369966747,\n",
       " 0.073901257865875966,\n",
       " 0.049508453486859796]"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.050945723516494033"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.98640000000000005"
      ]
     },
     "execution_count": 712,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = [metrics.log_loss(y_val, reduce_conf(pr)) for pr in pred_lst] \n",
    "sc\n",
    "pred = reduce_conf(np.mean(pred_lst, axis = 0))\n",
    "metrics.log_loss(y_val, pred)\n",
    "pred_class = (pred > 0.5).astype('float32')\n",
    "metrics.accuracy_score(y_val, pred_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 713,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_lst = [model.predict(aug_fun(X2_test, cr = (0.1,0.3))) for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 714,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred = reduce_conf(np.mean(pred_lst, axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 709,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 1)"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=12500, minmax=(array([  5.07297937e-09], dtype=float32), array([ 1.], dtype=float32)), mean=array([ 0.49884605], dtype=float32), variance=array([ 0.22398372], dtype=float32), skewness=array([ 0.00376293], dtype=float32), kurtosis=array([-1.93805027], dtype=float32))"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "DescribeResult(nobs=12500, minmax=(array([ 0.01], dtype=float32), array([ 0.99000001], dtype=float32)), mean=array([ 0.49890062], dtype=float32), variance=array([ 0.21772641], dtype=float32), skewness=array([ 0.00376109], dtype=float32), kurtosis=array([-1.94074309], dtype=float32))"
      ]
     },
     "execution_count": 709,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X2_test)\n",
    "pred.shape\n",
    "stats.describe(pred)\n",
    "pred = reduce_conf(pred)\n",
    "stats.describe(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 715,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12500, 1)"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>12500.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.499284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.472516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.010000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.470003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.990000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              label\n",
       "count  12500.000000\n",
       "mean       0.499284\n",
       "std        0.472516\n",
       "min        0.010000\n",
       "25%        0.010000\n",
       "50%        0.470003\n",
       "75%        0.990000\n",
       "max        0.990000"
      ]
     },
     "execution_count": 715,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_id = test_img_df.path.str.findall(r'(\\d+)\\.jpg').apply(lambda x: x[0])\n",
    "pred.shape\n",
    "subm_df = pd.DataFrame({'id':test_id, 'label':pred[:,0]})\n",
    "file = full_path('aug_fm_aug_test_fc_bin_m1.csv','subm')#aug_fm_aug_test\n",
    "subm_df.to_csv(file, index = False) \n",
    "subm_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1500, 15, 11, 512)"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2_val = conv_out.predict_generator(X_val)\n",
    "X2_val.shape\n",
    "X2_train = conv_out.predict(X_train)\n",
    "X2_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(616, 15, 11, 512)"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_train\n",
    "del X_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "del X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "665"
      ]
     },
     "execution_count": 669,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "139px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": false,
   "sideBar": false,
   "threshold": 4,
   "toc_cell": true,
   "toc_position": {
    "height": "40px",
    "left": "925.96px",
    "right": "20px",
    "top": "-0.048296px",
    "width": "171px"
   },
   "toc_section_display": "none",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
